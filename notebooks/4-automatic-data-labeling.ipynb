{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#!{sys.executable} -m pip install snorkel-metal\n",
    "#!{sys.executable} -m pip install tensorboardX\n",
    "#!{sys.executable} -m pip install git+https://github.com/HazyResearch/snorkel\n",
    "#!{sys.executable} -m pip install sqlalchemy\n",
    "#!{sys.executable} -m pip install matplotlib\n",
    "#!{sys.executable} -m pip install spacy\n",
    "#!{sys.executable} -m pip install lxml\n",
    "#!{sys.executable} -m pip install treedlib\n",
    "#!{sys.executable} -m pip install numba\n",
    "#!{sys.executable} -m pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "from metal.label_model import LabelModel\n",
    "from metal.analysis import lf_summary, label_coverage\n",
    "from metal.label_model.baselines import MajorityLabelVoter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/interim/kenya-positive.csv\")\n",
    "df_negative = pd.read_csv(\"../data/interim/kenya-neutral.csv\")\n",
    "df = df.append(df_negative, ignore_index = True)\n",
    "\n",
    "\n",
    "df['label'] = range(0, len(df))\n",
    "df = df[['label', 'sentences', 'class']]\n",
    "df.reset_index()\n",
    "df.to_csv('../data/interim/kenya.tsv', sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = df['class'].map({'n' : 0, 'i' : 1, 'd' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in df['sentences'][df['class'] == 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating labeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "incentive = {'fund established', 'market connection', 'low transaction cost',\n",
    "            'microfinance', 'payment system', 'financial support', 'grants',\n",
    "            'funded by', 'provide funding', 'support', 'bilateral', 'multilateral',\n",
    "            'capital', 'concessional', 'results based', 'mobilize', 'philanthropic',\n",
    "            'finance', 'credit', 'carbon market', 'provide investment oppportunities',\n",
    "            'offer incentives', 'generated funds', 'qualify for grants',\n",
    "            'will be funded', 'budgetary allocation', 'credit packages'}\n",
    "\n",
    "positive_words = {'established', 'created', 'improve', 'provide', 'mobilize', 'increase',\n",
    "                 'access to', 'implement'}\n",
    "\n",
    "negative_words = {'failed', 'there is not', 'there has not been', 'inadequate',\n",
    "                 'obstacles', 'barriers', 'obstacles'}\n",
    "\n",
    "disincentive = {'high transaction costs', 'barriers', 'levied', 'evasion', \n",
    "                'penalty', 'excise', 'seizure', 'fee', 'disincentive'}\n",
    "\n",
    "# Look for postitive words before incentives or the lack of negative words before incentives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTAIN = 0 \n",
    "POSITIVE = 1\n",
    "NEGATIVE = 2\n",
    "            \n",
    "INCENTIVE = r\"\"\"\\b(fund established|market connection|low transaction cost| microfinance|payment system|financial support|grants|\n",
    "                    funded by|provide funding|support|bilateral|multilateral|capital|concessional|results based|mobilize|philanthropic|\n",
    "                    finance|fund|credit|carbon market|provide investment opportunities|offer incentives|generated funds|\n",
    "                    qualify for grants|will be funded|budgetary allocation|credit packages|increase investment|\n",
    "                    carbon credit|transfer pricing|mobilization of financ|encourage investment|facilitate investment|\n",
    "                    access to finance|increased revenue|improving the lending|market access)\"\"\"\n",
    "\n",
    "def contains_positive_expressions(text):\n",
    "    return POSITIVE if re.search(INCENTIVE, text) else ABSTAIN\n",
    "\n",
    "LFs = [\n",
    "    contains_positive_expressions,\n",
    "]\n",
    "\n",
    "LF_names = [\n",
    "    'positive',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Ls_matrix(data, LFs):\n",
    "    noisy_labels = np.empty((len(data), len(LFs)))\n",
    "    for i, row in data.iteritems():\n",
    "        for j, lf in enumerate(LFs):\n",
    "            noisy_labels[i][j] = lf(row.lower())\n",
    "    return noisy_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[298,  13],\n",
       "       [ 57,  64]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LF_matrix = make_Ls_matrix(df['sentences'], LFs)\n",
    "gold_standard = np.array(df['class'])\n",
    "LF_matrix = LF_matrix.reshape((432,))\n",
    "\n",
    "confusion_matrix(LF_matrix, gold_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6464646464646465"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(LF_matrix, gold_standard)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "policy-toolkit",
   "language": "python",
   "name": "policy-toolkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
