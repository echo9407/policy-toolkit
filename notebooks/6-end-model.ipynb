{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End model to predict financial incentives and disincentives\n",
    "\n",
    "John Brandt\n",
    "\n",
    "Last updated: Aug 19, 2019\n",
    "\n",
    "\n",
    "This notebook contains a gold standard baseline (LSTM with gold standard labels) as well as a noisy implementation of snorkel labels with roBERTa encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, list_IDs, labels, mode):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        X = np.load('../data/processed/' + self.mode + '_embeddings/' + str(ID) + '.npy')\n",
    "        y = self.labels[ID]\n",
    "\n",
    "        return X.reshape((50, 1024)), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/gold_standard.csv\")\n",
    "gs_probas = np.load('../data/interim/snorkel_proba.npy')\n",
    "noisy_probas = np.load('../data/interim/snorkel_noisy_proba.npy')\n",
    "\n",
    "params = {'batch_size': 50,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 2}\n",
    "\n",
    "Y = df['class'] - 1\n",
    "    \n",
    "# Datasets\n",
    "partition = {'train': [x for x in range(0, 800)],\n",
    "             'validation': [x for x in range(800, 1000)]}\n",
    "\n",
    "noisy_labels = {k:w for w,k in zip(noisy_probas, range(1000))}\n",
    "gs_labels = {k:w for w,k in zip(Y, range(800, 1000))}\n",
    "\n",
    "# Generators\n",
    "training_set = Dataset(partition['train'], gs_probas[0:800], 'test')\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "validation_set = Dataset(partition['validation'], gs_labels, 'test')\n",
    "validation_generator = data.DataLoader(validation_set, **params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soft label loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class SoftCrossEntropyLoss(nn.Module):\n",
    "    \"\"\"Computes the CrossEntropyLoss while accepting probabilistic (float) targets\n",
    "    Args:\n",
    "        weight: a tensor of relative weights to assign to each class.\n",
    "            the kwarg name 'weight' is used to match CrossEntropyLoss\n",
    "        reduction: how to combine the elementwise losses\n",
    "            'none': return an unreduced list of elementwise losses\n",
    "            'mean': return the mean loss per elements\n",
    "            'sum': return the sum of the elementwise losses\n",
    "    Accepts:\n",
    "        input: An [n, k] float tensor of prediction logits (not probabilities)\n",
    "        target: An [n, k] float tensor of target probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, weight=None, reduction=\"mean\"):\n",
    "        super().__init__()\n",
    "        # Register as buffer is standard way to make sure gets moved /\n",
    "        # converted with the Module, without making it a Parameter\n",
    "        if weight is None:\n",
    "            self.weight = None\n",
    "        else:\n",
    "            # Note: Sets the attribute self.weight as well\n",
    "            self.register_buffer(\"weight\", torch.FloatTensor(weight))\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        n, k = input.shape\n",
    "        # Note that t.new_zeros, t.new_full put tensor on same device as t\n",
    "        cum_losses = input.new_zeros(n)\n",
    "        for y in range(k):\n",
    "            cls_idx = input.new_full((n,), y, dtype=torch.long)\n",
    "            y_loss = F.cross_entropy(input, cls_idx, reduction=\"none\")\n",
    "            if self.weight is not None:\n",
    "                y_loss = y_loss * self.weight[y]\n",
    "            cum_losses += target[:, y].float() * y_loss\n",
    "        if self.reduction == \"none\":\n",
    "            return cum_losses\n",
    "        elif self.reduction == \"mean\":\n",
    "            return cum_losses.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return cum_losses.sum()\n",
    "        else:\n",
    "            raise ValueError(f\"Unrecognized reduction: {self.reduction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(model, criterion, batch, targets):\n",
    "    pred = model(torch.autograd.Variable(batch))\n",
    "    loss = criterion(pred, torch.autograd.Variable(targets))\n",
    "    return pred, loss\n",
    "\n",
    "\n",
    "def train(model,\n",
    "         n_epochs,\n",
    "         train_generator,\n",
    "         val_generator):\n",
    "    \n",
    "    softcriterion = SoftCrossEntropyLoss()\n",
    "    hardcriterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.002)\n",
    "    counter = 0\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        for inputs, labels in train_generator:\n",
    "            counter += 1\n",
    "            model.zero_grad()\n",
    "            inputs = inputs.type(torch.FloatTensor)\n",
    "            pred, loss = apply(model, softcriterion, inputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if counter % print_every == 0:\n",
    "                # Get validation loss\n",
    "                val_h = model.init_hidden(batch_size)\n",
    "                val_losses = []\n",
    "                model.eval()\n",
    "                for inputs, labels in val_generator:\n",
    "                    inputs = inputs.type(torch.FloatTensor)\n",
    "                    output = model(inputs)\n",
    "                    val_loss = hardcriterion(output.reshape((batch_size, 3)), labels.long())\n",
    "                    val_losses.append(val_loss.item())\n",
    "\n",
    "                model.train()\n",
    "                print(\"Epoch: {}/{}...\".format(epoch+1, n_epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                      \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gold standard baseline\n",
    "\n",
    "Shallow RNN with RoBERTa encoded words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.autograd as autograd\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Defining the layers\n",
    "        # RNN Layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, self.output_size)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        self.hidden = self.init_hidden(batch.size(-2))\n",
    "        outputs, (ht, ct) = self.lstm(batch, self.hidden)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(ht[-1])\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return(autograd.Variable(torch.randn(1, batch_size, self.hidden_dim)),\n",
    "                                 autograd.Variable(torch.randn(1, batch_size, self.hidden_dim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_size = 1024, output_size = 3, hidden_dim = 200, n_layers = 1)\n",
    "model.to(\"cpu\")\n",
    "\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/250... Step: 100... Loss: 0.344589... Val Loss: 1.252464\n",
      "Epoch: 14/250... Step: 200... Loss: 0.342282... Val Loss: 1.358753\n",
      "Epoch: 20/250... Step: 300... Loss: 0.328632... Val Loss: 1.242303\n",
      "Epoch: 26/250... Step: 400... Loss: 0.283295... Val Loss: 1.359109\n",
      "Epoch: 33/250... Step: 500... Loss: 0.300449... Val Loss: 1.385932\n",
      "Epoch: 39/250... Step: 600... Loss: 0.310107... Val Loss: 1.391400\n",
      "Epoch: 45/250... Step: 700... Loss: 0.257704... Val Loss: 1.406703\n",
      "Epoch: 51/250... Step: 800... Loss: 0.256873... Val Loss: 1.419379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/john.brandt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/john.brandt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/john.brandt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/john.brandt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/john.brandt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/john.brandt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/john.brandt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/john.brandt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-8d2b5a2eb5c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m              \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m              \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m              val_generator = validation_generator)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-7744a10b9870>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, n_epochs, train_generator, val_generator)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "print_every = 100\n",
    "batch_size = 50\n",
    "\n",
    "model = train(model = model,\n",
    "             n_epochs = 250,\n",
    "             train_generator = training_generator,\n",
    "             val_generator = validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snorkel end model with RoBERTA-LSTM input module and noise-aware output head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['class'] - 1\n",
    "    \n",
    "# Datasets\n",
    "partition = {'train': [x for x in range(0, 15000)],\n",
    "             'validation': [x for x in range(0, 1000)]}\n",
    "\n",
    "noisy_labels = {k:w for w,k in zip(noisy_probas, range(15000))}\n",
    "gs_labels = {k:w for w,k in zip(Y, range(0, 1000))}\n",
    "\n",
    "# Generators\n",
    "training_set = Dataset(partition['train'], noisy_labels, 'train')\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "validation_set = Dataset(partition['validation'], gs_labels, 'test')\n",
    "validation_generator = data.DataLoader(validation_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/250... Step: 100... Loss: 0.528898... Val Loss: 1.002922\n",
      "Epoch: 2/250... Step: 200... Loss: 0.576691... Val Loss: 1.018679\n",
      "Epoch: 2/250... Step: 300... Loss: 0.472449... Val Loss: 1.097656\n",
      "Epoch: 3/250... Step: 400... Loss: 0.579681... Val Loss: 1.114452\n",
      "Epoch: 3/250... Step: 500... Loss: 0.586448... Val Loss: 1.136326\n",
      "Epoch: 3/250... Step: 600... Loss: 0.521979... Val Loss: 1.020871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/john.brandt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/john.brandt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/john.brandt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/john.brandt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/john.brandt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/john.brandt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/john.brandt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/john.brandt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2afbf5a0b940>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m              \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m              \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m              val_generator = validation_generator)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-7744a10b9870>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, n_epochs, train_generator, val_generator)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Model(input_size = 1024, output_size = 3, hidden_dim = 200, n_layers = 1)\n",
    "model.to(\"cpu\")\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "device = \"cpu\"\n",
    "print_every = 100\n",
    "batch_size = 50\n",
    "\n",
    "model = train(model = model,\n",
    "             n_epochs = 250,\n",
    "             train_generator = training_generator,\n",
    "             val_generator = validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do: Snorkel end model with RoBERTa-LSTM input module and multi-task output head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do: Snorkel end model with RoBERTa-LSTM input module and multi-task output head, with concatenation of additional feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do: Snorkel end model with RoBERTa-LSTM input module and multi-task output head, with concatenation of additional feature engineering and synonym augmentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "policy-toolkit",
   "language": "python",
   "name": "policy-toolkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
